{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bdf1426",
   "metadata": {},
   "source": [
    "# Enunciado\n",
    "Hola ingeniero . Bienvenido a tu sexto desafio! Ya sabes que en [Vault-Tec Corporation](https://fallout.fandom.com/es/wiki/Vault-Tec_Corporation) tenemos sensores encargados de monitorear las condiciones actuales de nuestros refugios. En ocasiones pasadas detectamos que varios de ellos presentaban fallas recurrentes, impidiendo que pudieramos determinar las condiciones de nuestros b贸vedas y darle la seguridad esperada a nuestros clientes en un mundo post apocaliptico . \n",
    "\n",
    "Anteriormente, a pedido de nuestro equipo, solucionamos algunos errores detectados en el funcionamiento de nuestro codigo y generamos pruebas unitarias; ademas, modificamos el codigo para que usara vectores de Numpy en lugar de listas nativas de Python, evidenciando una clara mejora en los tiempos de ejecucion tomados. \n",
    "\n",
    "Uno de los desarrolladores Senior nos ha sugerido hacer pruebas de rendimiento usando el modulo Pandas. Para ello nos ha indicado que modifiquemos todas las partes del codigo que usan vectores de numpy por **Dataframes de Pandas.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b53d424",
   "metadata": {},
   "source": [
    "# Insumos\n",
    "Tu equipo te ha dado el siguiente codigo el cual deberas modificar. \n",
    "\n",
    "**IMPORTANTE:** En la vida real lo comun es que pases mas tiempo leyendo codigo de otros, que escribiendolo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00ad01e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import date\n",
    "from os.path import abspath\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NumpyLogExtractor:\n",
    "    \"\"\"Clase para extraer y filtrar logs desde un archivo JSON.\"\"\"\n",
    "\n",
    "    def __init__(self, file_path: str):\n",
    "        \"\"\"\n",
    "        Inicializa el extractor de logs con la ruta del archivo.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Ruta del archivo JSON que contiene los logs.\n",
    "        \"\"\"\n",
    "        self.file_abspath = abspath(file_path)\n",
    "\n",
    "    def from_file(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Carga los logs desde el archivo JSON especificado en la inicializaci贸n.\n",
    "\n",
    "        Returns:\n",
    "            list[Log]: Lista de instancias de Log extra铆das del archivo.\n",
    "        \"\"\"\n",
    "        log_dtype: list[tuple] = [\n",
    "            (\"sensor_id\", \"U16\"),\n",
    "            (\"date\", \"M8[D]\"),  # fecha con resoluci贸n de d铆as\n",
    "            (\"event_type\", \"U16\"),\n",
    "            (\"duration_seconds\", \"f8\"),\n",
    "        ]\n",
    "\n",
    "        with open(self.file_abspath) as file:\n",
    "            raw_logs: list[dict] = json.load(file)\n",
    "        logs = np.array(\n",
    "            [\n",
    "                (\n",
    "                    log[\"sensor_id\"],\n",
    "                    np.datetime64(log[\"timestamp\"]),\n",
    "                    log[\"event_type\"],\n",
    "                    float(log[\"duration_seconds\"]),\n",
    "                )\n",
    "                for log in raw_logs\n",
    "            ],\n",
    "            dtype=log_dtype,\n",
    "        )\n",
    "        return logs\n",
    "\n",
    "    @staticmethod\n",
    "    def fetch_logs_on_date(\n",
    "        target_date: date, logs: np.ndarray, sensor_id: int | None = None\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Filtra los logs que corresponden a una fecha y, opcionalmente, a un sensor espec铆fico.\n",
    "\n",
    "        Args:\n",
    "            target_date (date): Fecha objetivo para filtrar los logs.\n",
    "            logs (list[Log]): Lista de logs disponibles.\n",
    "            sensor_id (Optional[int], optional): ID del sensor para filtrar.\n",
    "                Si es None, se incluyen logs de todos los sensores. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            list[Log]: Lista de logs que cumplen con los filtros aplicados.\n",
    "        \"\"\"\n",
    "        mask = logs[\"date\"] == np.datetime64(target_date)\n",
    "        if sensor_id is not None:\n",
    "            mask &= logs[\"sensor_id\"] == sensor_id\n",
    "        return logs[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b78e7663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NumpySensorFailureAnalyzer:\n",
    "    \"\"\"Clase para analizar fallos de sensores a partir de registros de eventos usando NumPy.\"\"\"\n",
    "\n",
    "    WEEK_TOTAL_SECONDS: int = 7 * 24 * 60 * 60\n",
    "    \"\"\"N煤mero total de segundos en una semana.\"\"\"\n",
    "\n",
    "    def __init__(self, logs: np.ndarray):\n",
    "        \"\"\"Inicializa el analizador con los registros de logs.\n",
    "\n",
    "        Args:\n",
    "            logs (np.ndarray): Array estructurado de logs con dtype:\n",
    "                [\n",
    "                    (\"sensor_id\", \"i4\"),\n",
    "                    (\"date\", \"M8[D]\"),\n",
    "                    (\"event_type\", \"U16\"),\n",
    "                    (\"duration_seconds\", \"f8\"),\n",
    "                ]\n",
    "        \"\"\"\n",
    "        self.logs = logs\n",
    "\n",
    "    def get_sensor_failure_duration(self, sensor_id: int, searched_date: date) -> float | None:\n",
    "        \"\"\"Obtiene la duraci贸n total del fallo de un sensor en una fecha espec铆fica.\"\"\"\n",
    "        mask = (self.logs[\"sensor_id\"] == sensor_id) & (\n",
    "            self.logs[\"date\"].astype(\"datetime64[D]\") == np.datetime64(searched_date)\n",
    "        )\n",
    "        logs_on_date = self.logs[mask]\n",
    "\n",
    "        if logs_on_date.size == 0:\n",
    "            return None\n",
    "\n",
    "        failure_start = logs_on_date[logs_on_date[\"event_type\"] == \"FAILURE_START\"][\n",
    "            \"duration_seconds\"\n",
    "        ]\n",
    "        failure_end = logs_on_date[logs_on_date[\"event_type\"] == \"FAILURE_END\"][\"duration_seconds\"]\n",
    "\n",
    "        start_time = failure_start[0] if failure_start.size > 0 else 0.0\n",
    "        end_time = failure_end[0] if failure_end.size > 0 else 0.0\n",
    "\n",
    "        return abs(end_time - start_time)\n",
    "\n",
    "    def get_weekly_sensor_failure_duration(\n",
    "        self, sensor_id: int, start_date: date, end_date: date | None = None\n",
    "    ) -> list[dict]:\n",
    "        \"\"\"Obtiene la duraci贸n diaria de fallos de un sensor durante una semana.\"\"\"\n",
    "        end_date = start_date + timedelta(7) if end_date is None else end_date\n",
    "        searched_week = [\n",
    "            start_date + timedelta(days=i) for i in range((end_date - start_date).days)\n",
    "        ]\n",
    "\n",
    "        return [\n",
    "            {\n",
    "                \"sensor_id\": sensor_id,\n",
    "                \"date\": str(day),\n",
    "                \"failure_seconds\": self.get_sensor_failure_duration(sensor_id, day),\n",
    "            }\n",
    "            for day in searched_week\n",
    "        ]\n",
    "\n",
    "    def get_weekly_sensor_failure_probability(self, sensor_id: int, start_date: date) -> list[dict]:\n",
    "        \"\"\"Calcula la probabilidad diaria de fallo de un sensor durante una semana.\"\"\"\n",
    "        weekly_durations = self.get_weekly_sensor_failure_duration(sensor_id, start_date)\n",
    "        return [\n",
    "            {\n",
    "                \"sensor_id\": sensor_id,\n",
    "                \"date\": x[\"date\"],\n",
    "                \"failure_probability\": f\"{(x['failure_seconds'] or 0) / self.WEEK_TOTAL_SECONDS:.4f}\",\n",
    "            }\n",
    "            for x in weekly_durations\n",
    "        ]\n",
    "\n",
    "    def get_conditional_failure_probability(\n",
    "        self,\n",
    "        sensor_a_id: int,\n",
    "        sensor_b_id: int,\n",
    "        start_date: date,\n",
    "        failure_minutes_threshold: float | None = 3,\n",
    "    ) -> float:\n",
    "        \"\"\"Calcula la probabilidad condicional de que un sensor falle dado que otro sensor fall贸.\"\"\"\n",
    "        threshold = failure_minutes_threshold * 60\n",
    "\n",
    "        sensor_b_week = self.get_weekly_sensor_failure_duration(sensor_b_id, start_date)\n",
    "        count_b_failures = sum(\n",
    "            1 for x in sensor_b_week if x[\"failure_seconds\"] and x[\"failure_seconds\"] >= threshold\n",
    "        )\n",
    "        if count_b_failures == 0:\n",
    "            return 0.0\n",
    "\n",
    "        sensor_a_week = self.get_weekly_sensor_failure_duration(sensor_a_id, start_date)\n",
    "        count_a_b_failures = sum(\n",
    "            1\n",
    "            for x, y in zip(sensor_a_week, sensor_b_week, strict=False)\n",
    "            if x[\"failure_seconds\"]\n",
    "            and y[\"failure_seconds\"]\n",
    "            and x[\"failure_seconds\"] >= threshold\n",
    "            and y[\"failure_seconds\"] >= threshold\n",
    "        )\n",
    "\n",
    "        return count_a_b_failures / count_b_failures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d057a94",
   "metadata": {},
   "source": [
    "# Tu turno!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfda8c8d",
   "metadata": {},
   "source": [
    "Ahora es tu turno! Evaluemos el rendimiento de nuestro codigo actual contra la modificacion sugerida por nuestro compa帽ero de equipo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b9b956",
   "metadata": {},
   "source": [
    "## 1. Benchmarking de LogExtractor\n",
    "Reescribamos, probemos y comparemos los tiempos de ejecucion de la clase `NumpyLogExtractor` que tenemos en este momento, contra una version de esta clase modificada para usar Dataframes de Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79073d90",
   "metadata": {},
   "source": [
    "**Reescribiendo la clase NumpyLogExtractor:** Reescribe la clase NumpyLogExtractor para que use Dataframes de Pandas en lugar de vectores de Numpy.\n",
    "1. Nombra la nueva clase PandasLogExtractor. \n",
    "2. Modifica las funciones de esta clase que retornan `numpy.ndarray` para que retornen `pandas.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac3c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu codigo aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec474b0",
   "metadata": {},
   "source": [
    "Comparemos el tiempo de ejecucion de nuestra clase NumpyLogExtractor pasada contra esta nueva implementacion en Pandas para la funcion `fetch_logs_on_date`.\n",
    "- Consejo 1: Extrae los logs con ambas clases en una celda diferente a donde vayas a ejecutar `fetch_logs_on_date`; de no hacerlo, la medida del tiempo de ejecucion se vera contaminada con el tiempo tomado por la funcion de extraccion de logs.\n",
    "- Consejo 2: Busca sobre magics proporcionadas por Jupyter para medicion de tiempos y como usarlas. Consulta sobre `%%timeit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a5bb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu codigo aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4183672",
   "metadata": {},
   "source": [
    "## 2. Benchmarking de SensorFailureAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2884e194",
   "metadata": {},
   "source": [
    "Reescribamos, probemos y comparemos los tiempos de ejecucion de la clase `NumpySensorFailureAnalyzer` que tenemos en este momento, contra una version de esta clase modificada para usar dataframes de Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4872eaaf",
   "metadata": {},
   "source": [
    "**Reescribiendo la clase SensorFailureAnalyzer:** Reescribe la clase NumpySensorFailureAnalyzer para que use Datafarmes de Pandas en lugar de vectores de Numpy\n",
    "1. Nombra la nueva clase PandasSensorFailureAnalyzer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1834a44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu codigo aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b172a15",
   "metadata": {},
   "source": [
    "Comparemos el tiempo de ejecucion de nuestra clase SensorFailureAnalyzer pasada contra esta nueva implementacion en Numpy para la funcion `get_weekly_sensor_failure_probability`.\n",
    "- Consejo 1: Usa los logs anteriormente extraidos e instancia (crea) ambas clases en una celda diferente a donde vayas a ejecutar `get_weekly_sensor_failure_probability`; de no hacerlo, la medida del tiempo de ejecucion se vera contaminada con el tiempo tomado para crear las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50760bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu codigo aqui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HenryLectures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
