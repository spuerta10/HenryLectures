{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bdf1426",
   "metadata": {},
   "source": [
    "# Enunciado\n",
    "Hola ingeniero 👋. Bienvenido a tu quinto desafio! Ya sabes que en [Vault-Tec Corporation](https://fallout.fandom.com/es/wiki/Vault-Tec_Corporation) tenemos sensores encargados de monitorear las condiciones actuales de nuestros refugios. En ocasiones pasadas detectamos que varios de ellos presentaban fallas recurrentes, impidiendo que pudieramos determinar las condiciones de nuestros bóvedas y darle la seguridad esperada a nuestros clientes en un mundo post apocaliptico 🙃. \n",
    "\n",
    "Anteriormente, a pedido de nuestro equipo, solucionamos algunos errores detectados en el funcionamiento de nuestro codigo; ademas, generamos pruebas unitarias.\n",
    "\n",
    "Luego de tener las bases correctamente montadas (codigo + pruebas uitarias), nuestro equipo nos ha pedido indagar en un tema importantisimo: tratar de mejorar el rendimiento de nuestro codigo, tambien conocido como benchmarking. \n",
    "\n",
    "Uno de los desarrolladores Senior nos ha sugerido hacer pruebas de rendimiento usando el modulo Numpy. Para ello nos ha indicado que modifiquemos todas las partes del codigo que usan listas nativas de Python por **arrays de Numpy.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b53d424",
   "metadata": {},
   "source": [
    "# Insumos\n",
    "Tu equipo te ha dado el siguiente codigo el cual deberas modificar. \n",
    "\n",
    "**IMPORTANTE:** En la vida real lo comun es que pases mas tiempo leyendo codigo de otros, que escribiendolo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e45d9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import Literal\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Log(BaseModel):\n",
    "    \"\"\"Representa un registro (log) generado por un sensor.\n",
    "\n",
    "    Atributos:\n",
    "        sensor_id (Literal): Identificador del sensor que generó el registro.\n",
    "            Valores posibles: \"oxy_guard\", \"thermo_core\", \"hidra_flow\", \"radi_shield\".\n",
    "        event_type (Literal): Tipo de evento registrado.\n",
    "            Valores posibles: \"FAILURE_START\" (inicio de falla) o \"FAILURE_END\" (fin de falla).\n",
    "        timestamp (datetime): Fecha y hora exacta en que ocurrió el evento.\n",
    "        duration_seconds (int): Duración de la falla en segundos. En caso de ser \"FAILURE_START\",\n",
    "            puede ser 0 si aún no ha finalizado la falla.\n",
    "    \"\"\"\n",
    "\n",
    "    sensor_id: Literal[\"oxy_guard\", \"thermo_core\", \"hidra_flow\", \"radi_shield\"]\n",
    "    event_type: Literal[\"FAILURE_END\", \"FAILURE_START\"]\n",
    "    timestamp: datetime\n",
    "    duration_seconds: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95dfc829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import date\n",
    "from os.path import abspath\n",
    "\n",
    "\n",
    "class LogExtractor:\n",
    "    \"\"\"Clase para extraer y filtrar logs desde un archivo JSON.\"\"\"\n",
    "\n",
    "    def __init__(self, file_path: str):\n",
    "        \"\"\"\n",
    "        Inicializa el extractor de logs con la ruta del archivo.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Ruta del archivo JSON que contiene los logs.\n",
    "        \"\"\"\n",
    "        self.file_abspath = abspath(file_path)\n",
    "\n",
    "    def from_file(self) -> list[\"Log\"]:\n",
    "        \"\"\"\n",
    "        Carga los logs desde el archivo JSON especificado en la inicialización.\n",
    "\n",
    "        Returns:\n",
    "            list[Log]: Lista de instancias de Log extraídas del archivo.\n",
    "        \"\"\"\n",
    "        with open(self.file_abspath) as file:\n",
    "            raw_logs: list[dict] = json.load(file)\n",
    "        logs: list[Log] = [Log(**log) for log in raw_logs]\n",
    "        return logs\n",
    "\n",
    "    @staticmethod\n",
    "    def fetch_logs_on_date(\n",
    "        target_date: date, logs: list[\"Log\"], sensor_id: int | None = None\n",
    "    ) -> list[\"Log\"]:\n",
    "        \"\"\"\n",
    "        Filtra los logs que corresponden a una fecha y, opcionalmente, a un sensor específico.\n",
    "\n",
    "        Args:\n",
    "            target_date (date): Fecha objetivo para filtrar los logs.\n",
    "            logs (list[Log]): Lista de logs disponibles.\n",
    "            sensor_id (Optional[int], optional): ID del sensor para filtrar.\n",
    "                Si es None, se incluyen logs de todos los sensores. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            list[Log]: Lista de logs que cumplen con los filtros aplicados.\n",
    "        \"\"\"\n",
    "        logs_on_date: list[Log] = list(\n",
    "            filter(\n",
    "                lambda x: (\n",
    "                    x.timestamp.date() == target_date\n",
    "                    and (sensor_id is None or x.sensor_id == sensor_id)\n",
    "                ),\n",
    "                logs,\n",
    "            )\n",
    "        )\n",
    "        return logs_on_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2310170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "\n",
    "class SensorFailureAnalyzer:\n",
    "    \"\"\"Clase para analizar fallos de sensores a partir de registros de eventos.\n",
    "\n",
    "    Esta clase permite calcular la duración de fallos de sensores,\n",
    "    la probabilidad de fallo semanal y la probabilidad condicional\n",
    "    de que un sensor falle dado que otro sensor también falló.\n",
    "    \"\"\"\n",
    "\n",
    "    WEEK_TOTAL_SECONDS: int = 7 * 24 * (60**2)\n",
    "    \"\"\"int: Número total de segundos en una semana.\"\"\"\n",
    "\n",
    "    def __init__(self, logs: list[Log]):\n",
    "        \"\"\"Inicializa el analizador con los registros de logs.\n",
    "\n",
    "        Args:\n",
    "            logs (list[Log]): Lista de objetos `Log` que contienen los eventos de los sensores.\n",
    "        \"\"\"\n",
    "        self.logs = logs\n",
    "\n",
    "    def get_sensor_failure_duration(self, sensor_id: str, searched_date: date) -> float | None:\n",
    "        \"\"\"Obtiene la duración total del fallo de un sensor en una fecha específica.\n",
    "\n",
    "        Busca en los logs los eventos `FAILURE_START` y `FAILURE_END`\n",
    "        del sensor en la fecha indicada y calcula el tiempo total en segundos.\n",
    "\n",
    "        Args:\n",
    "            sensor_id (str): Identificador del sensor a analizar.\n",
    "            searched_date (date): Fecha para la que se quiere obtener la duración del fallo.\n",
    "\n",
    "        Returns:\n",
    "            float | None: Duración del fallo en segundos.\n",
    "            Devuelve `None` si no hay logs del sensor en esa fecha.\n",
    "        \"\"\"\n",
    "        logs_on_date: list[Log] = LogExtractor.fetch_logs_on_date(\n",
    "            sensor_id=sensor_id, target_date=searched_date, logs=self.logs\n",
    "        )\n",
    "\n",
    "        if not logs_on_date:\n",
    "            return None\n",
    "\n",
    "        failure_start_time: float = next(\n",
    "            (log.duration_seconds for log in logs_on_date if log.event_type == \"FAILURE_START\"), 0\n",
    "        )\n",
    "        failure_end_time: float = next(\n",
    "            (log.duration_seconds for log in logs_on_date if log.event_type == \"FAILURE_END\"), 0\n",
    "        )\n",
    "\n",
    "        return abs(failure_end_time - failure_start_time)\n",
    "\n",
    "    def get_weekly_sensor_failure_duration(\n",
    "        self, sensor_id: int, start_date: date, end_date: date | None = None\n",
    "    ) -> list[dict]:\n",
    "        \"\"\"Obtiene la duración diaria de fallos de un sensor durante una semana.\n",
    "\n",
    "        Args:\n",
    "            sensor_id (int): Identificador del sensor.\n",
    "            start_date (date): Fecha de inicio del periodo.\n",
    "            end_date (Optional[date], optional): Fecha final del periodo.\n",
    "                Si no se proporciona, se toma `start_date + 7 días`.\n",
    "\n",
    "        Returns:\n",
    "            list[dict]: Lista de diccionarios con la siguiente información:\n",
    "                - \"sensor_id\" (int): Identificador del sensor.\n",
    "                - \"date\" (str): Fecha en formato ISO (YYYY-MM-DD).\n",
    "                - \"failure_seconds\" (float | None): Duración del fallo en segundos.\n",
    "        \"\"\"\n",
    "        end_date = start_date + timedelta(7) if end_date is None else end_date\n",
    "        searched_week: list[date] = [\n",
    "            (start_date + timedelta(days=i)) for i in range((end_date - start_date).days)\n",
    "        ]\n",
    "        return [\n",
    "            {\n",
    "                \"sensor_id\": sensor_id,\n",
    "                \"date\": str(date),\n",
    "                \"failure_seconds\": self.get_sensor_failure_duration(\n",
    "                    sensor_id=sensor_id, searched_date=date\n",
    "                ),\n",
    "            }\n",
    "            for date in searched_week\n",
    "        ]\n",
    "\n",
    "    def get_weekly_sensor_failure_probability(self, sensor_id: int, start_date: date) -> list[dict]:\n",
    "        \"\"\"Calcula la probabilidad diaria de fallo de un sensor durante una semana.\n",
    "\n",
    "        La probabilidad se calcula como la proporción del tiempo en fallo\n",
    "        respecto al total de segundos en una semana.\n",
    "\n",
    "        Args:\n",
    "            sensor_id (int): Identificador del sensor.\n",
    "            start_date (date): Fecha de inicio del periodo.\n",
    "\n",
    "        Returns:\n",
    "            list[dict]: Lista de diccionarios con la siguiente información:\n",
    "                - \"sensor_id\" (int): Identificador del sensor.\n",
    "                - \"date\" (str): Fecha en formato ISO (YYYY-MM-DD).\n",
    "                - \"failure_probability\" (str): Probabilidad del fallo (0 a 1) con 4 decimales.\n",
    "        \"\"\"\n",
    "        weekly_sensor_failure_duration = self.get_weekly_sensor_failure_duration(\n",
    "            sensor_id, start_date\n",
    "        )\n",
    "        return [\n",
    "            {\n",
    "                \"sensor_id\": sensor_id,\n",
    "                \"date\": x[\"date\"],\n",
    "                \"failure_probability\": f\"{x['failure_seconds'] / self.WEEK_TOTAL_SECONDS:.4f}\",\n",
    "            }\n",
    "            for x in weekly_sensor_failure_duration\n",
    "        ]\n",
    "\n",
    "    def get_conditional_failure_probability(\n",
    "        self,\n",
    "        sensor_a_id: int,\n",
    "        sensor_b_id: int,\n",
    "        start_date: date,\n",
    "        failure_minutes_threshold: float | None = 3,\n",
    "    ) -> float:\n",
    "        \"\"\"Calcula la probabilidad condicional de que un sensor falle dado que otro sensor falló.\n",
    "\n",
    "        Se considera que un sensor falló en un día si su duración de fallo\n",
    "        es mayor o igual a un umbral en minutos.\n",
    "\n",
    "        Fórmula:\n",
    "            P(A|B) = (Número de días donde A y B fallaron) / (Número de días donde B falló)\n",
    "\n",
    "        Args:\n",
    "            sensor_a_id (int): Identificador del sensor A (sensor condicionado).\n",
    "            sensor_b_id (int): Identificador del sensor B (sensor condicionante).\n",
    "            start_date (date): Fecha de inicio del periodo.\n",
    "            failure_minutes_threshold (Optional[float], optional): Umbral de fallo en minutos.\n",
    "                Defaults a 3 minutos.\n",
    "\n",
    "        Returns:\n",
    "            float: Probabilidad condicional P(A|B) como un valor entre 0 y 1.\n",
    "            Devuelve 0 si B nunca falló en el periodo.\n",
    "        \"\"\"\n",
    "        failure_seconds_threshold = failure_minutes_threshold * 60\n",
    "\n",
    "        sensor_b_weekly_failures = self.get_weekly_sensor_failure_duration(sensor_b_id, start_date)\n",
    "        count_sensor_b_failures = sum(\n",
    "            1\n",
    "            for x in sensor_b_weekly_failures\n",
    "            if x[\"failure_seconds\"] and x[\"failure_seconds\"] >= failure_seconds_threshold\n",
    "        )\n",
    "\n",
    "        if count_sensor_b_failures == 0:\n",
    "            return 0.0\n",
    "\n",
    "        sensor_a_weekly_failures = self.get_weekly_sensor_failure_duration(sensor_a_id, start_date)\n",
    "        count_sensor_a_b_failures = sum(\n",
    "            1\n",
    "            for x, y in zip(sensor_a_weekly_failures, sensor_b_weekly_failures, strict=False)\n",
    "            if x[\"failure_seconds\"]\n",
    "            and y[\"failure_seconds\"]\n",
    "            and x[\"failure_seconds\"] >= failure_seconds_threshold\n",
    "            and y[\"failure_seconds\"] >= failure_seconds_threshold\n",
    "        )\n",
    "\n",
    "        return count_sensor_a_b_failures / count_sensor_b_failures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d057a94",
   "metadata": {},
   "source": [
    "# Tu turno!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfda8c8d",
   "metadata": {},
   "source": [
    "Ahora es tu turno! Evaluemos el rendimiento de nuestro codigo actual contra la modificacion sugerida por nuestro compañero de equipo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b9b956",
   "metadata": {},
   "source": [
    "## 1. Benchmarking de LogExtractor\n",
    "Reescribamos, probemos y comparemos los tiempos de ejecucion de la clase `LogExtractor` que tenemos en este momento, contra una version de esta clase modificada para usar vectores de Numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79073d90",
   "metadata": {},
   "source": [
    "**Reescribiendo la clase LogExtractor:** Reescribe la clase LogExtractor para que use vectores de Numpy en lugar de listas nativas de Python\n",
    "1. Nombra la nueva clase NumpyLogExtractor. \n",
    "2. Modifica las funciones de esta clase que retornan `list[Log]` para que retornen `numpy.ndarray`.\n",
    "\n",
    "- Consejo: Puedes prescindir de la clase Log. Busca sobre como representar un objeto en numpy.\n",
    "    ```python\n",
    "    log_dtype: list[tuple] = [\n",
    "            (\"sensor_id\", \"i4\"),\n",
    "            (\"date\", \"M8[D]\"),  # fecha con resolución de días\n",
    "            (\"event_type\", \"U16\"), \n",
    "            (\"duration_seconds\", \"f8\"),\n",
    "        ]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dedec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu codigo aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec474b0",
   "metadata": {},
   "source": [
    "Comparemos el tiempo de ejecucion de nuestra clase LogExtractor pasada contra esta nueva implementacion en Numpy para la funcion `fetch_logs_on_date`.\n",
    "- Consejo 1: Extrae los logs con ambas clases en una celda diferente a donde vayas a ejecutar `fetch_logs_on_date`; de no hacerlo, la medida del tiempo de ejecucion se vera contaminada con el tiempo tomado por la funcion de extraccion de logs.\n",
    "- Consejo 2: Busca sobre magics proporcionadas por Jupyter para medicion de tiempos y como usarlas. Consulta sobre `%%timeit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e058bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.09 μs ± 486 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Tu codigo aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4183672",
   "metadata": {},
   "source": [
    "## 2. Benchmarking de SensorFailureAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2884e194",
   "metadata": {},
   "source": [
    "Reescribamos, probemos y comparemos los tiempos de ejecucion de la clase `SensorFailureAnalyzer` que tenemos en este momento, contra una version de esta clase modificada para usar vectores de Numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4872eaaf",
   "metadata": {},
   "source": [
    "**Reescribiendo la clase SensorFailureAnalyzer:** Reescribe la clase SensorFailureAnalyzer para que use vectores de Numpy en lugar de listas nativas de Python\n",
    "1. Nombra la nueva clase NumpySensorFailureAnalyzer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fb4c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu codigo aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b172a15",
   "metadata": {},
   "source": [
    "Comparemos el tiempo de ejecucion de nuestra clase SensorFailureAnalyzer pasada contra esta nueva implementacion en Numpy para la funcion `get_weekly_sensor_failure_probability`.\n",
    "- Consejo 1: Usa los logs anteriormente extraidos e instancia (crea) ambas clases en una celda diferente a donde vayas a ejecutar `get_weekly_sensor_failure_probability`; de no hacerlo, la medida del tiempo de ejecucion se vera contaminada con el tiempo tomado para crear las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c778a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu codigo aqui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HenryLectures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
